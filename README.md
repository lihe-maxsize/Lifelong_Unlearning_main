# LLaVA Lifelong Unlearning
This codebase is developed based on the LLaVA source code. 
To use it, please install all the environment dependencies required by LLaVA.

# The MLUBench
The QA pairs of Tasks are in the "Tasks" folder of the MLUBench.zip.

The QA pairs of each entity are in the "Entities" folder of the MLUBench.zip.

The images are available at this anonymous URL https://1drv.ms/f/c/419e3e9d51ec307d/ErRa7jkzxZhGvZlmLoGfuNIBsQ_fk3PcbOZzryhBuX47ig?e=MUuXwA

# Unlearning
The code for baseline unlearning is in unlearning_auto.py.

# Eval
The code for model evaluation (get model response) is in eval_unlearned_model.py.

# Metrics
The code for automatic evaluation of model responses is in metrics.py.

# Gate Module
The code for automatic entity extraction of GLM and task match is in entity_extract.py.

# LUMoE
The code for the LUMoE method is in LUMoE.py.



